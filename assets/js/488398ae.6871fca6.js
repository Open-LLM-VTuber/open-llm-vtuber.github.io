"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[7149],{5684:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>d,contentTitle:()=>o,default:()=>h,frontMatter:()=>l,metadata:()=>i,toc:()=>c});var i=s(1256),t=s(4848),r=s(8453);const l={title:"1.0.1 \u7248\u672c\u53d1\u5e03",description:"Version 1.0.1 Release",slug:"v1.0.1-release",authors:["tim","ethan"],tags:["release"],image:"https://i.imgur.com/mErPwqL.png",hide_table_of_contents:!1},o="Open-LLM-VTuber v1.0.1 Release \ud83d\udca5",d={authorsImageUrls:[void 0,void 0]},c=[{value:"\u2728 Highlights",id:"-highlights",level:2},{value:"\ud83d\udccb Detailed Changes",id:"-detailed-changes",level:2},{value:"\ud83e\uddee Backend",id:"-backend",level:3},{value:"\ud83d\udda5\ufe0f Frontend",id:"\ufe0f-frontend",level:3},{value:"\ud83d\udcd6 Documentation",id:"-documentation",level:3},{value:"\ud83e\uddf9 Cleanup",id:"-cleanup",level:3},{value:"\u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f Critical Upgrade Notice",id:"\ufe0f\ufe0f\ufe0f-critical-upgrade-notice",level:2},{value:"Why the Hassle? \ud83d\udca1",id:"why-the-hassle-",level:3},{value:"\ud83c\udf89 Contributors",id:"-contributors",level:2},{value:"Faster download links for Chinese users \u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684(\u76f8\u5bf9)\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5",id:"faster-download-links-for-chinese-users-\u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684\u76f8\u5bf9\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5",level:2}];function a(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsxs)(n.p,{children:["This release marks a significant milestone for Open-LLM-VTuber, featuring a complete rewrite of the backend and frontend with over 240+ new commits, along with numerous enhancements and new features. If you were using a version before this, version ",(0,t.jsx)(n.code,{children:"v1.0.0"})," is basically a new app."]}),"\n",(0,t.jsxs)(n.p,{children:["\u26a0\ufe0f Direct upgrades from older versions are impossible due to architectural changes. Please refer to our ",(0,t.jsx)(n.strong,{children:(0,t.jsx)(n.a,{href:"https://open-llm-vtuber.github.io/docs/intro",children:"new documentation site"})})," for installation."]}),"\n",(0,t.jsx)(n.p,{children:"(v1.0.0 had a bug after the release, so let's just ignore that and have the v1.0.1)"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/06eff9dc-e141-4401-90ac-823b08662aae",alt:"i4_pet_desktop"})}),(0,t.jsx)(n.th,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/e0175aa3-62c8-4cde-9c6f-5d010727c04f",alt:"i1"})})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/082d8f29-9b48-4dbb-87f6-0f12d89a92f2",alt:"i3"})}),(0,t.jsx)(n.td,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/f6b50eda-8187-4d37-b39b-a34e33683328",alt:"i2"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/fa4a5884-0ec7-4377-8a3b-204aafaf8ede",alt:"i4"})}),(0,t.jsx)(n.td,{style:{textAlign:"center"},children:(0,t.jsx)(n.img,{src:"https://github.com/user-attachments/assets/8e0819d2-75dd-4ebf-97ab-399bf2d01795",alt:"i3_browser_world_fun"})})]})]})]}),"\n",(0,t.jsx)(n.h2,{id:"-highlights",children:"\u2728 Highlights"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Vision Capability:"})," Video chat with the AI."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Desktop Pet Mode:"})," A new Desktop Pet Mode lets you have your VTuber companion directly on your desktop."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Brand New Frontend:"}),"  A completely redesigned frontend built with React, ChakuraUI, and Vite offers a modern user experience. Available as web and desktop apps, located in the ",(0,t.jsx)(n.a,{href:"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web",children:"Open-LLM-VTuber-Web"})," repository."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Chat History Management:"}),"  Implemented a system to store and retrieve conversation history, enabling persistent interactions with your AI."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"New LLM support:"}),"  Many new (stateless) LLM providers are now supported (and refactored), including Ollama, OpenAI, Gemini, Claude, Mistral, DeepSeek, Zhipu, and llama.cpp."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"DeepSeek R1 Reasoning model support"}),": The reasoning chain will be displayed but not spoken. See your waifu's inner thoughts!"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Major Backend Rewrite:"})," The core of Open-LLM-VTuber has been rebuilt from the ground up, focusing on asynchronous operations, improved memory management, and a more modular architecture."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Refactored Configuration:"})," The ",(0,t.jsx)(n.code,{children:"conf.yaml"})," file was restructured, and ",(0,t.jsx)(n.code,{children:"config_alts"})," has been renamed to ",(0,t.jsx)(n.code,{children:"characters"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TTS Preprocessor"}),": Text inside ",(0,t.jsx)(n.code,{children:"asterisks"}),", ",(0,t.jsx)(n.code,{children:"brackets"}),", ",(0,t.jsx)(n.code,{children:"parentheses"}),", and ",(0,t.jsx)(n.code,{children:"angle brackets"})," will no longer be spoken by the TTS."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Dependency management:"})," Switched to ",(0,t.jsx)(n.code,{children:"uv"})," for dependency management, removed unused dependencies such as ",(0,t.jsx)(n.code,{children:"rich"}),", ",(0,t.jsx)(n.code,{children:"playsound3"}),", and ",(0,t.jsx)(n.code,{children:"sounddevice"}),"."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Documentation Site:"})," A comprehensive documentation site is now live at ",(0,t.jsx)(n.a,{href:"https://open-llm-vtuber.github.io/",children:"https://open-llm-vtuber.github.io/"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"-detailed-changes",children:"\ud83d\udccb Detailed Changes"}),"\n",(0,t.jsx)(n.h3,{id:"-backend",children:"\ud83e\uddee Backend"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Architecture:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["The project structure has been reorganized to use the ",(0,t.jsx)(n.code,{children:"src/"})," directory."]}),"\n",(0,t.jsx)(n.li,{children:"The backend is now fully asynchronous, improving responsiveness."}),"\n",(0,t.jsxs)(n.li,{children:["CLI mode (",(0,t.jsx)(n.code,{children:"main.py"}),") has been removed."]}),"\n",(0,t.jsx)(n.li,{children:'The "exit word" has been removed.'}),"\n",(0,t.jsxs)(n.li,{children:["Models are initialized and managed using ",(0,t.jsx)(n.code,{children:"ServiceContext"}),", offering better memory management, particularly when switching characters."]}),"\n",(0,t.jsxs)(n.li,{children:["Refactored LLMs into ",(0,t.jsx)(n.code,{children:"agent"})," and ",(0,t.jsx)(n.code,{children:"stateless_llm"}),", supporting a wider range of LLMs with a new agent interface: ",(0,t.jsx)(n.code,{children:"basic_memory_agent"})," and ",(0,t.jsx)(n.code,{children:"hume_ai_agent"}),"."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"LLM (Language Model) Enhancements:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"New (and old but refactored) providers: Ollama, OpenAI (and any OpenAI Compatible API), Gemini, Claude, Mistral, DeepSeek, Zhipu, llama.cpp."}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"temperature"})," parameter added."]}),"\n",(0,t.jsx)(n.li,{children:"No more tokens will be generated after interruption, improving the responsiveness of voice interruption."}),"\n",(0,t.jsx)(n.li,{children:"Ollama models are preloaded at startup, kept in memory for the server's duration, and unloaded at exit."}),"\n",(0,t.jsxs)(n.li,{children:["Added a ",(0,t.jsx)(n.code,{children:"hf_mirror"})," flag to specify whether to use the Hugging Face mirror source."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"TTS (Text-to-Speech) Enhancements:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"TTS now generates multiple audio segments concurrently and sends them sequentially, reducing latency."}),"\n",(0,t.jsx)(n.li,{children:"New interruption logic for smoother transitions."}),"\n",(0,t.jsxs)(n.li,{children:["Added filters (",(0,t.jsx)(n.code,{children:"asterisks"}),", ",(0,t.jsx)(n.code,{children:"brackets"}),", ",(0,t.jsx)(n.code,{children:"parentheses"}),") to prevent unwanted text from being spoken."]}),"\n",(0,t.jsxs)(n.li,{children:["Implemented ",(0,t.jsx)(n.code,{children:"faster_first_response"})," feature to prioritize the synthesis and playback of the first sentence fragment, minimizing latency."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ASR (Automatic Speech Recognition) Enhancements:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Made Sherpa-onnx ASR with the ",(0,t.jsx)(n.strong,{children:"SenseVoiceSmall int8"})," model the default for both English and Chinese presets, with automatic model download."]}),"\n",(0,t.jsxs)(n.li,{children:["Added a ",(0,t.jsx)(n.code,{children:"provider"})," option for sherpa-onnx-asr."]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Other Improvements:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Chat log persistence is used to maintain conversation history."}),"\n",(0,t.jsxs)(n.li,{children:["All ",(0,t.jsx)(n.code,{children:"print"})," statements are replaced with ",(0,t.jsx)(n.code,{children:"loguru"})," for structured logging."]}),"\n",(0,t.jsxs)(n.li,{children:["Added a Chinese configuration preset: ",(0,t.jsx)(n.code,{children:"conf.CN.yaml"}),"."]}),"\n",(0,t.jsx)(n.li,{children:"Basic AI proactive speaking (experimental)."}),"\n",(0,t.jsx)(n.li,{children:"Added some checks in the CI/CD process"}),"\n",(0,t.jsx)(n.li,{children:"Added input/output type system to agents"}),"\n",(0,t.jsxs)(n.li,{children:["Added ",(0,t.jsx)(n.strong,{children:"Tencent Translate"})," in ",(0,t.jsx)(n.a,{href:"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/107",children:"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/107"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"\ufe0f-frontend",children:"\ud83d\udda5\ufe0f Frontend"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.strong,{children:"New frontend built with Electron, React, ChakuraUI, and Vite."})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Multi-Mode in Single Codebase:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Web Mode: Browser interface"}),"\n",(0,t.jsx)(n.li,{children:"Window Mode: Desktop window"}),"\n",(0,t.jsx)(n.li,{children:"Pet Mode: Transparent desktop companion"}),"\n",(0,t.jsx)(n.li,{children:"Seamless context sharing between Window and Pet modes, allowing for the preservation of settings, history, connections, and model states."}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Enhanced UI Features"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Responsive layout with collapsible sidebar and footer"}),"\n",(0,t.jsx)(n.li,{children:"Customizable Live2D model interactions: Mouse tracking for eye movement, Click-triggered animations, Drag & resize capabilities."}),"\n",(0,t.jsx)(n.li,{children:"Persistent local storage for user preference settings, including background, VAD configuration, Live2D size and interactions, and agent behavior."}),"\n",(0,t.jsx)(n.li,{children:"Supports viewing, loading, and deleting conversation history with streaming subtitles."}),"\n",(0,t.jsx)(n.li,{children:"(Electron pet-mode) A transparent, always-on-top desktop companion with click-through, non-interactive areas featuring draggable and hideable Live2D and UI, right-click menu controls."}),"\n",(0,t.jsx)(n.li,{children:"Camera and screen capturing panel"}),"\n",(0,t.jsx)(n.li,{children:"Switch characters easily"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-documentation",children:"\ud83d\udcd6 Documentation"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Rewritten README file."}),"\n",(0,t.jsx)(n.li,{children:"New comprehensive documentation with a dedicated website."}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"-cleanup",children:"\ud83e\uddf9 Cleanup"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Removed unused and legacy code, including ",(0,t.jsx)(n.code,{children:"TaskQueue.py"}),", ",(0,t.jsx)(n.code,{children:"scripts/install_piper_tts.py"}),", ",(0,t.jsx)(n.code,{children:"model_manager_old.py"}),", ",(0,t.jsx)(n.code,{children:"service_context_old.py"}),", ",(0,t.jsx)(n.code,{children:"main.py"}),", ",(0,t.jsx)(n.code,{children:"asr_with_vad"}),", ",(0,t.jsx)(n.code,{children:"vad"}),", ",(0,t.jsx)(n.code,{children:"start_cli"}),", ",(0,t.jsx)(n.code,{children:"fake_llm"}),", ",(0,t.jsx)(n.code,{children:"MemGPT"}),", the ",(0,t.jsx)(n.code,{children:"pywhispercpp"})," submodule, and CoreML script."]}),"\n",(0,t.jsxs)(n.li,{children:["Removed unused dependencies: ",(0,t.jsx)(n.code,{children:"rich"}),", ",(0,t.jsx)(n.code,{children:"playsound3"}),", ",(0,t.jsx)(n.code,{children:"sounddevice"}),", among others."]}),"\n",(0,t.jsxs)(n.li,{children:["Removed configuration options that are no longer relevant: ",(0,t.jsx)(n.code,{children:"VOICE_INPUT_ON"}),", ",(0,t.jsx)(n.code,{children:"MIC_IN_BROWSER"}),", ",(0,t.jsx)(n.code,{children:"LIVE2D"}),", ",(0,t.jsx)(n.code,{children:"EXTRA_SYSTEM_PROMPT_RAG"}),", ",(0,t.jsx)(n.code,{children:"AI_NAME"}),", ",(0,t.jsx)(n.code,{children:"USER_NAME"}),", ",(0,t.jsx)(n.code,{children:"SAVE_CHAT_HISTORY"}),", ",(0,t.jsx)(n.code,{children:"CHAT_HISTORY_DIR"}),", ",(0,t.jsx)(n.code,{children:"RAG_ON"}),", ",(0,t.jsx)(n.code,{children:"LLMASSIST_RAG_ON"}),", ",(0,t.jsx)(n.code,{children:"SAY_SENTENCE_SEPARATELY"}),", ",(0,t.jsx)(n.code,{children:"MEMORY_SNAPSHOT"}),", ",(0,t.jsx)(n.code,{children:"PRELOAD_MODELS"}),", ",(0,t.jsx)(n.code,{children:"tts_on"}),"."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"\ufe0f\ufe0f\ufe0f-critical-upgrade-notice",children:"\u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f Critical Upgrade Notice"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"No Direct Upgrades - Previous installations are incompatible"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Fresh Install Required - Follow new documentation"}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsx)(n.p,{children:"Config Changes - Back up existing configurations before migration"}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"why-the-hassle-",children:"Why the Hassle? \ud83d\udca1"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"UV dependency manager replaces legacy systems"}),"\n",(0,t.jsx)(n.li,{children:"Complete configuration schema overhaul"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Please check out the ",(0,t.jsx)(n.a,{href:"https://open-llm-vtuber.github.io/docs/quick-start/",children:"new documentation"})," to install Open-LLM-VTuber again. Fortunately, thanks to ",(0,t.jsx)(n.code,{children:"uv,"})," there should be fewer headaches during installation."]}),"\n",(0,t.jsx)(n.h2,{id:"-contributors",children:"\ud83c\udf89 Contributors"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"@t41372, which is me"}),"\n",(0,t.jsxs)(n.li,{children:["@ylxmf2005, the creator of the new frontend, implemented LLM vision capability, chat history management, TTS concurrency, hume AI agent, better sentence division, a better live2d configuration, countless bug fixes, and more. He also wrote the majority of the documentation and provided countless insights. The version ",(0,t.jsx)(n.code,{children:"v1.0.0"})," was a close collaboration with him and wouldn't have existed without his tremendous contribution."]}),"\n",(0,t.jsxs)(n.li,{children:["@Stewitch, who added the hf_mirror option and is currently working on a launcher for this project to streamline the installation and configuration process. It's still a work in progress but will be completed very soon. ",(0,t.jsx)(n.a,{href:"https://github.com/Stewitch/LiZhen",children:"https://github.com/Stewitch/LiZhen"})]}),"\n",(0,t.jsx)(n.li,{children:"@Fluchw, who added Tecent translator and helped us fix the translator bug."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"And all the other contributors who worked on this project in previous versions."}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Full Changelog"}),": ",(0,t.jsx)(n.a,{href:"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/compare/v0.5.2...v1.0.0",children:"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/compare/v0.5.2...v1.0.0"})]}),"\n",(0,t.jsx)(n.h2,{id:"faster-download-links-for-chinese-users-\u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684\u76f8\u5bf9\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5",children:"Faster download links for Chinese users \u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684(\u76f8\u5bf9)\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5"}),"\n",(0,t.jsx)(n.p,{children:"Open-LLM-VTuber-v1.0.3.zip (\u5305\u542b sherpa onnx asr \u7684 sense-voice \u6a21\u578b\uff0c\u5c31\u4e0d\u7528\u518d\u4ecegithub\u4e0a\u62c9\u53d6\u4e86)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/Open-LLM-VTuber-v1.0.3.zip",children:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/Open-LLM-VTuber-v1.0.3.zip"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"open-llm-vtuber-electron-1.0.0-frontend.exe (\u684c\u9762\u7248\u524d\u7aef\uff0cWindows)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0-setup.exe",children:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0-setup.exe"})}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"open-llm-vtuber-electron-1.0.0-frontend.dmg (\u684c\u9762\u7248\u524d\u7aef\uff0cmacOS)"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0.dmg",children:"https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0.dmg"})}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(a,{...e})}):a(e)}},8453:(e,n,s)=>{s.d(n,{R:()=>l,x:()=>o});var i=s(6540);const t={},r=i.createContext(t);function l(e){const n=i.useContext(r);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:l(e.components),i.createElement(r.Provider,{value:n},e.children)}},1256:e=>{e.exports=JSON.parse('{"permalink":"/blog/v1.0.1-release","editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/blog/2025-02-04-v1-0-1-release.md","source":"@site/blog/2025-02-04-v1-0-1-release.md","title":"1.0.1 \u7248\u672c\u53d1\u5e03","description":"Version 1.0.1 Release","date":"2025-02-04T00:00:00.000Z","tags":[{"inline":false,"label":"Release","permalink":"/blog/tags/release","description":"Version Release Note"}],"readingTime":5.53,"hasTruncateMarker":true,"authors":[{"name":"Yi-Ting Chiu","title":"yey","url":"https://github.com/t41372","page":{"permalink":"/blog/authors/tim"},"socials":{"github":"https://github.com/t41372"},"imageURL":"https://github.com/t41372.png","key":"tim"},{"name":"Ethan Lee","title":"qwq","url":"https://github.com/ylxmf2005","page":{"permalink":"/blog/authors/ethan"},"socials":{"github":"https://github.com/ylxmf2005"},"imageURL":"https://github.com/ylxmf2005.png","key":"ethan"}],"frontMatter":{"title":"1.0.1 \u7248\u672c\u53d1\u5e03","description":"Version 1.0.1 Release","slug":"v1.0.1-release","authors":["tim","ethan"],"tags":["release"],"image":"https://i.imgur.com/mErPwqL.png","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"1.1.0 Release","permalink":"/blog/v1.1.0-release"}}')}}]);