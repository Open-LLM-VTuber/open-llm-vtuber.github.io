"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5983],{8222:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>c,default:()=>p,frontMatter:()=>i,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"user-guide/backend/structure","title":"Backend Architecture Overview","description":"Core Component Interaction Flow","source":"@site/i18n/en/docusaurus-plugin-content-docs/current/user-guide/backend/structure.md","sourceDirName":"user-guide/backend","slug":"/user-guide/backend/structure","permalink":"/en/docs/user-guide/backend/structure","draft":false,"unlisted":false,"editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/docs/user-guide/backend/structure.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docSidebar","previous":{"title":"\u540e\u7aef\u7528\u6237\u6307\u5357","permalink":"/en/docs/user-guide/backend"},"next":{"title":"Configuration file","permalink":"/en/docs/user-guide/backend/config"}}');var o=t(4848),a=t(8453);const i={sidebar_position:1},c="Backend Architecture Overview",s={},d=[{value:"Core Component Interaction Flow",id:"core-component-interaction-flow",level:2},{value:"Code Structure",id:"code-structure",level:2}];function u(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",mermaid:"mermaid",pre:"pre",...(0,a.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(n.header,{children:(0,o.jsx)(n.h1,{id:"backend-architecture-overview",children:"Backend Architecture Overview"})}),"\n",(0,o.jsx)(n.h2,{id:"core-component-interaction-flow",children:"Core Component Interaction Flow"}),"\n",(0,o.jsx)(n.mermaid,{value:"sequenceDiagram\n    participant User\n    participant Live2D\n    participant Frontend\n    participant WebSocket\n    participant Backend\n    participant ASR\n    participant Agent\n    participant Translator\n    participant TTS\n\n    User->>Frontend: Speak/Input text\n    \n    alt Voice input\n        Frontend->>WebSocket: Send audio data\n        WebSocket->>Backend: Forward audio data\n        Backend->>ASR: Speech recognition\n        ASR--\x3e>Backend: Return text\n    else Text input\n        Frontend->>WebSocket: Send text data\n    end\n\n    Backend->>Agent: Process user input\n    Note over Agent: 1. Compatible with multiple types of Agents<br>2. Save conversation history\n    \n    loop For each sentence\n        Agent--\x3e>Backend: Generate reply text\n        opt Translation needed\n            Backend->>Translator: Translate reply text\n            Translator--\x3e>Backend: Return translated text\n        end\n        Backend->>TTS: Text-to-speech\n        TTS--\x3e>Backend: Return audio\n        Backend->>WebSocket: Send audio and expression data\n        WebSocket->>Frontend: Forward data\n        Frontend->>User: Play audio\n        Frontend->>Live2D: Control model expressions\n        Live2D--\x3e>User: Display animation effects\n    end\n\n    Note over Frontend,Backend: The entire process supports:<br>1. Interrupting conversations<br>2. Switching character configurations<br>3. History management"}),"\n",(0,o.jsx)(n.h2,{id:"code-structure",children:"Code Structure"}),"\n",(0,o.jsx)(n.pre,{children:(0,o.jsx)(n.code,{children:"\u251c\u2500\u2500 background/                # Background image resource directory\n\u251c\u2500\u2500 characters/               # Character configuration file directory\n\u251c\u2500\u2500 frontend/                # Frontend page file directory\n\u251c\u2500\u2500 live2d-models/           # Live2D model resource directory\n\u251c\u2500\u2500 logs/                    # Log file directory\n\u251c\u2500\u2500 models/                  # AI model file directory\n\u251c\u2500\u2500 prompts/                 # Prompt template directory\n\u2502   \u251c\u2500\u2500 presona/            # Character persona prompts\n\u2502   \u251c\u2500\u2500 utils/              # Utility prompts\n\u2502   \u2514\u2500\u2500 prompt_loader.py    # Prompt loader\n\u251c\u2500\u2500 src/                     # Source code directory\n\u2502   \u2514\u2500\u2500 open_llm_vtuber/    # Main code package\n\u2502       \u251c\u2500\u2500 agent/          # AI dialogue agent module\n\u2502       \u2502   \u251c\u2500\u2500 agents/     # Different types of dialogue agent implementations\n\u2502       \u2502   \u2514\u2500\u2500 stateless_llm/  # Stateless LLM interface implementation\n\u2502       \u251c\u2500\u2500 asr/            # Speech recognition module\n\u2502       \u251c\u2500\u2500 tts/            # Text-to-speech module\n\u2502       \u251c\u2500\u2500 chat_history_manager.py  # Chat history manager\n\u2502       \u251c\u2500\u2500 conversation.py          # Conversation management\n\u2502       \u251c\u2500\u2500 live2d_model.py          # Live2D model manager\n\u2502       \u251c\u2500\u2500 routes.py                # FastAPI route definitions\n\u2502       \u251c\u2500\u2500 server.py                # WebSocket server\n\u2502       \u2514\u2500\u2500 service_context.py       # Service context manager\n\u251c\u2500\u2500 conf.yaml                # Default configuration file\n\u2514\u2500\u2500 run_server.py           # Startup script\n"})})]})}function p(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,o.jsx)(n,{...e,children:(0,o.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>i,x:()=>c});var r=t(6540);const o={},a=r.createContext(o);function i(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:i(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);