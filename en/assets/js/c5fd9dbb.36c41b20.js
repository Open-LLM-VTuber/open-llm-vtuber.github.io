"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5418],{930:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/v1.0.0-release","metadata":{"permalink":"/en/blog/v1.0.0-release","editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/blog/v1.0.0-release.md","source":"@site/blog/v1.0.0-release.md","title":"v1.0.0 \u6b63\u5f0f\u53d1\u5e03","description":"","date":"2025-08-15T03:58:31.000Z","tags":[],"readingTime":0.015,"hasTruncateMarker":true,"authors":[{"name":"Yi-Ting Chiu","title":"yey","url":"https://github.com/t41372","page":{"permalink":"/en/blog/authors/tim"},"socials":{"github":"https://github.com/t41372"},"imageURL":"https://github.com/t41372.png","key":"tim"},{"name":"Ethan Lee","title":"qwq","url":"https://github.com/ylxmf2005","page":{"permalink":"/en/blog/authors/ethan"},"socials":{"github":"https://github.com/ylxmf2005"},"imageURL":"https://github.com/ylxmf2005.png","key":"ethan"}],"frontMatter":{"title":"v1.0.0 \u6b63\u5f0f\u53d1\u5e03","authors":["tim","ethan"]},"unlisted":false,"nextItem":{"title":"1.2.0 Release","permalink":"/en/blog/v1.2.0-release"}},"content":"\x3c!-- truncate --\x3e"},{"id":"v1.2.0-release","metadata":{"permalink":"/en/blog/v1.2.0-release","editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/blog/2025-08-03-v1-2-0-release.md","source":"@site/i18n/en/docusaurus-plugin-content-blog/2025-08-03-v1-2-0-release.md","title":"1.2.0 Release","description":"Version 1.2.0 Release","date":"2025-08-03T00:00:00.000Z","tags":[{"inline":false,"label":"Release","permalink":"/en/blog/tags/release","description":"Version Release Note"}],"readingTime":11.49,"hasTruncateMarker":true,"authors":[{"name":"Yi-Ting Chiu","title":"yey","url":"https://github.com/t41372","page":{"permalink":"/en/blog/authors/tim"},"socials":{"github":"https://github.com/t41372"},"imageURL":"https://github.com/t41372.png","key":"tim"},{"name":"Ethan Lee","title":"qwq","url":"https://github.com/ylxmf2005","page":{"permalink":"/en/blog/authors/ethan"},"socials":{"github":"https://github.com/ylxmf2005"},"imageURL":"https://github.com/ylxmf2005.png","key":"ethan"}],"frontMatter":{"title":"1.2.0 Release","description":"Version 1.2.0 Release","slug":"v1.2.0-release","authors":["tim","ethan"],"tags":["release"],"image":"https://i.imgur.com/mErPwqL.png","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"v1.0.0 \u6b63\u5f0f\u53d1\u5e03","permalink":"/en/blog/v1.0.0-release"},"nextItem":{"title":"1.1.0 Release","permalink":"/en/blog/v1.1.0-release"}},"content":"This is a substantial update, packed with major features including Letta-based long-term memory, MCP support, Live2D Cubism 5 support, Chinese support for the frontend, an improved update system, a Bilibili Danmaku client, and numerous bug fixes.\\n\\nFirst, we\'d like to apologize for the extended release cycle. We will do our best to avoid such long intervals between updates in the future.\\n\\nAdditionally, please note a licensing change for the project\'s frontend (the `Open-LLM-VTuber-Web` repository, which powers the built-in web and Electron clients). Effective with this release (v1.2.0), the frontend will transition from unspecified license (all rights reserved) to the `Open-LLM-VTuber License 1.0`.\\n\\nThe backend will remain under the MIT License for v1.2.0 but is expected to be unified under the `Open-LLM-VTuber License 1.0` around v1.3 or v1.4. We are still discussing the specifics and will provide a clear announcement in the GitHub Release when the change occurs. Please be aware that Live2D models have their own licenses, which you should check separately.\\n\\n### \u26a0\ufe0f Notice: Potential Breaking Changes\\n\\nIn this version, we have refactored the Live2D implementation to add support for Live2D 5.0 models and fix display issues with many existing models. As part of this change, **support for Live2D 2.1 models has been removed**. While this should increase compatibility with modern models, if you encounter any issues with your Live2D model not displaying after updating, please let us know and consider rolling back to the previous version.\\n\\n## \u2728 Highlights\\n\\n-   **(MCP)** The AI can now call tools that support the Model-Context Protocol (MCP). Built-in support is included for [time](https://github.com/modelcontextprotocol/servers/tree/main/src/time) and [ddg-search](https://github.com/nickclyde/duckduckgo-mcp-server). The frontend now displays the status of tool calls. (See the Appendix for a demo).\\n-   **(MCP)** Added support for BrowserBase\'s Browser Use MCP with a [Live View](https://docs.browserbase.com/features/session-live-view) in the frontend.\\n-   **(Live2D)** The frontend Live2D SDK has been migrated from `pixi-live2d-display-lipsync` to the official Live2D Web SDK. This adds support for Cubism 5 but removes support for Cubism 2. Models now have improved feedback on click interactions.\\n-   The default Live2D model has been changed to `mao_pro`, as the expressions for the `shizuku` model were removed by the official creators in the Live2D 5 version.\\n-   **(Frontend)** Added Chinese language support.\\n-   Implemented an interface for live streaming platforms and added a client for receiving Bilibili Danmaku (live comments).\\n-   **(Memory)** Implemented Letta-based long-term memory.\\n-   **(LLM)** Added support for LM Studio.\\n-   **(TTS)** Added support for OpenAI-Compatible TTS, SparkTTS, and SiliconFlow TTS.\\n-   Added a `requirements.txt` file for users who are not familiar with `pip` commands or prefer not to use `uv`.\\n-   Numerous bug fixes.\\n-   Updated the documentation, which now includes an \\"Ask AI\\" feature.\\n\\n\x3c!-- truncate --\x3e\\n\\n## Detailed Changes Since v1.1.0:\\n\\n### Backend:\\n\\n-   Changed some preset options in the configuration file: `llm_provider` -> `ollama_llm`.\\n-   Set `project_id` and `organization_id` in `conf.yaml` to `null` by default to prevent API errors.\\n-   Azure ASR: Added a list for detected languages and fixed several bugs.\\n-   Fixed bugs related to configuration file updates (2bc0c1b5f75ea79f563935b03a2267e6584d9bc @ylxmf2005).\\n-   To allow Windows users to confidently use backslashes for file paths, all double quotes in the configuration file have been changed to single quotes (758d0b304bfa9d2c561987e9d3edac74857309c7).\\n-   Fixed Claude\'s vision capabilities. It seems this was never working correctly\u2014did no one notice until now?\\n-   Information about Live2D models can now be fetched from the `GET /live2d-models/info` route.\\n-   When using the update script, the frontend (linked via git submodule) will now be updated as well.\\n-   Fixed [#150](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/150): The `temperature` parameter was not passed during the initialization of OpenAI-Compatible LLMs.\\n-   Fixed [#141](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/141): A dependency issue on Intel Macs.\\n-   Implemented a live streaming platform interface and a Bilibili Danmaku client based on [blivedm](https://github.com/xfgryujk/blivedm/tree/dev) (fea16ace015851656e6c044961758c69247ce69e), [#142](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/142) @Fluchw, @ylxmf2005.\\n-   Merged [#161](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/161), adding the `StatelessLLMWithTemplate` class. Thanks, @aaronchantrill!\\n-   Added OpenAI-Compatible TTS [#178](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/178). Thanks, @fastfading!\\n-   Implemented Letta-based long-term memory [#179](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/179). Thanks, @rayburstray! See the [Letta Agent docs](https://open-llm-vtuber.github.io/docs/user-guide/backend/agent#letta-agent).\\n-   Added LM Studio LLM support (b971867b231dac5f3e9e14a28e6c4124fa592a72).\\n-   Added `requirements.txt` and documentation for installing with `pip` and `conda` in the Quick Start guide (044e5ba9aaab9de8fae440f54e6667c63ab89b85).\\n-   Added Spark TTS [#182](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/182) (@Because66666), SiliconFlow TTS [#208](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/208) (@endtower), and MiniMax TTS [#214](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/214) (@Y0oMu).\\n-   Fixed an issue where FunASR could not run offline (Issue [#7](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/7), fixed in [#214](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/214) by @Y0oMu).\\n-   Added prompt configuration for whisper, fast-whisper, and whisper.cpp [#214](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/214) @Y0oMu.\\n-   Fixed [#159]: Resolved an error caused by empty chunks returned from third-party OpenAI-compatible APIs [#184](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/184) @872226263.\\n-   \u2728 Feature Enhancement: Implemented MCP Plus [#185](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/185) @Stewitch @ylxmf2005.\\n-   Fixed bugs related to AI group chat (4da3c82e6388604dc0817927a7f07796ef524785 @ylxmf2005).\\n-   Fixed a bug that could cause garbled text in `conf.yaml` when merging configurations (67e1622891e264cc71b6da71533a3be188a09692).\\n-   Added a DuckDuckGo-based web search MCP tool (3904419fb9f0b67e5f22027e183741cc0f1719dc @ylxmf2005).\\n-   Fixed a bug where auto language detection could not be selected for faster-whisper (#188).\\n-   Added a configurable prompt in `conf.yaml` for the AI\'s proactive speech (Issue [#190](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/190) @ylxmf2005).\\n-   Added a status bar for MCP function calls (51adb61895f1e5040e238fa1c97acdeefe9e2690 @ylxmf2005).\\n-   Added an optional prompt for speaking style (0a76ac69b04d288c102ec52423d927a4ab9a246d @ylxmf2005).\\n-   Implemented browser control capabilities via Stagehand: The AI can now operate a web browser (1dc2055d74d342202d4a54ea96109d3cfaa7bee7 @ylxmf2005).\\n-   Implemented a backend check to automatically pull the `frontend` submodule, preventing issues where the frontend code is missing.\\n\\n### Frontend (@ylxmf2005):\\n\\n-   Adopted a mode-management system and added a button in the Window mode UI to switch modes directly.\\n-   Added support for playing \\"Talk\\" motion groups when the model is speaking (to create a swaying effect). A guide on how to use this will be available in v1.3.\\n-   Migrated the Live2D SDK from `pixi-live2d-display-lipsync` to the official Live2D Web SDK (supports Cubism 5, drops Cubism 2). Note: This was developed using a beta version of the SDK from another project and does not yet support motionsync.\\n-   Added i18n support for Chinese.\\n-   Refactored VAD dependency static files from being loaded via CDN to being referenced from the local build output ([#5](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web/pull/5) @East333, [#7](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web/pull/7) @charliedcc).\\n-   Fixed a \\"404 Not Found\\" bug for an invalid CSS link ([#2](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web/pull/2) @East333).\\n-   Added a \\"Click-through\\" toggle switch for Desktop Pet mode.\\n-   Removed the \\"follow mouse\\" feature. The \\"Pointer Interactive\\" setting now only controls whether clicks trigger actions, which must be configured in `model_dict`.\\n-   Fixed a bug where the fallback avatar failed to display in the history area.\\n-   Fixed a bug with abnormal mouse click-through behavior in Desktop Pet mode.\\n-   Added a status display for when the AI is using tools.\\n-   Added a Browser Live View Panel based on BrowserBase.\\n-   Fixed a conflict between expression display and blinking (Issue [#105](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/105)).\\n-   Updated VAD to the latest version and used the new `onSpeechRealStart` event to prevent misfires that could interrupt the AI\'s response ([Commit 445dc86](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web/commit/445dc8661b83357416ca848fddcaa07afc1433e1)).\\n-   Added settings to limit the size and dimensions of images sent to the backend (Issue [#209](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/issues/209)).\\n\\n>:warning: there are way too many pull requests and contributions. If I happen to miss anyone, please let me know.\\n\\n## What\'s Next: A Look at v1.3-v1.4\\n\\n-   **Streaming TTS:** We plan to add streaming support for major TTS models, which will significantly reduce response latency.\\n-   **Hume AI Changes:** The Hume AI Agent will be removed and replaced with an option for Hume AI API TTS (the official TTS API was released recently). Hume AI\'s emotion control and naturalness are the best I\'ve seen (though it\'s also the priciest at $200/1M characters vs. Fish Audio at $15/1M).\\n-   **Natural Motion:** We will provide examples and tutorials for achieving natural, neuro-sama-like idle swaying motions.\\n-   **`motionMap` Feature:** Similar to `emotionMap`, this will allow the model to perform actions while speaking.\\n-   **One-Click Character Import.**\\n-   **MCP Bridge Support:** We\'ll add a demo for a decoupled MCP setup, where the MCP Server & Client run on the user\'s machine. The main server will provide a ready-to-use bridge to push MCP commands via WebSocket and receive results.\\n-   **Character Status Panel:** A new UI area to display and manage the character\'s state (e.g., mood, affinity, current thoughts, what they are doing). This highly customizable state will influence the character\'s behavior. The \\"thinking\\" tag will likely be moved here (planned for v1.4).\\n\\n## Upcoming License Change Notice (v1.3-v1.4)\\n\\nAs the project grows, we plan to adjust our licensing model to better support its long-term sustainability.\\n\\nStarting from a future version (the exact version will be clearly announced, likely around v1.3.0), the Open-LLM-VTuber project will adopt a modified Apache 2.0 license with the following terms:\\n\\n-   **Unified License:** The entire project (both frontend and backend) will be under a single, modified Apache 2.0 license.\\n-   **Clear Usage Scope:** The new license will clarify permitted uses and commercial activities that require a separate license.\\n\\n### How does this affect you?\\n\\nFor most users, including streamers, educators, and researchers, there is no impact.\\n\\nThe software is licensed under Apache 2.0 with the following additional terms:\\n\\n\u2705 **Uses that DO NOT require a separate license:**\\n-   All non-commercial purposes (e.g., personal projects, education, academic research, non-profit activities).\\n-   Using the software for VTuber streaming and video creation (e.g., on YouTube, Twitch, Bilibili).\\n\\n\u274c **Uses that DO require a commercial license:**\\n-   Providing paid access, subscriptions, or hosting services (including offering the software as a SaaS, paid download, or online service).\\n-   Redistributing, reselling, rebranding, or repackaging the software for commercial purposes.\\n-   Integrating the software into a commercial product that is sold or licensed for a fee (including both software and hardware).\\n\\nFor full details, please refer to the `LICENSE` file in the frontend repository and the specific release notes when the backend license is updated.\\n\\n### Why are we planning this change?\\n\\nThe primary reasons for this adjustment are:\\n\\n1.  Our frontend previously lacked a specific license, which led to instances of our software being repackaged, rebranded, and deployed commercially without attribution.\\n2.  We may develop a SaaS offering in the future. We want to protect the software we\'ve invested significant effort in from being directly copied into a competing product.\\n\\n**Please note: Even if we launch a SaaS, we have no plans to close-source the core Open-LLM-VTuber project, nor do we intend to change its ability to run completely offline and locally. We deeply value the trust we have built within the open-source community.** Even if we were to close-source it one day, you would still be able to use older, open-licensed versions.\\n\\n**An open-source license is an agreement that binds both users and developers.** I can guarantee we will not delete the repository, barring unforeseen circumstances (and even then, GitHub\'s fork mechanism makes deletion largely symbolic).\\n\\nThe core purpose of exploring a SaaS model is to make the project sustainable and to better realize our vision for AI companionship. There may come a day when we, the core developers, no longer have the time and energy to maintain Open-LLM-VTuber. Or perhaps a better, more advanced solution will emerge from the community, and our project will be consigned to the annals of history. But I hope that day is far off.\\n\\nRegarding project sustainability, I\'ve considered two paths. One is the SaaS model mentioned above. The other is to better enable contributors to participate in our development, improving our efficiency and developer retention. I will be making progress on this front after the v1.2 release.\\n\\nThe decision to change the license stems from observing multiple incidents of open-source misuse and license violations across the community. After seeing these events, we\'ve come to feel that the MIT license may not align with our ideal expectations. A license should reflect the core developers\' intent for how their code is used, serving as a protection and a set of boundaries for both developers and users. Due to my own oversight in the beginning, I chose a license without fully considering the project\'s potential scale `(I just picked MIT without much thought, never imagining the project would get this big)`. To ensure our contributors can continue to code without worry and that our users understand the intended boundaries of use, we have decided to amend our license.\\n\\nIn fact, our React-based frontend (since v1.0.0) has never had a specified license. According to [GitHub\'s documentation](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository#choosing-the-right-license), if a repository has no license, we retain full copyright (which is effectively closed-source). We want to clarify our licensing terms moving forward.\\n\\nDuring this process, we considered various options and looked at the approaches taken by other open-source projects like Dify and LobeHub, striving to avoid negative impacts on our regular users and open-source contributors.\\n\\n## Which files should I get?\\n\\n### For Existing Open-LLM-VTuber Users (v1.0.0 or newer)\\n1.  Run `uv run upgrade.py` to update to the latest version.\\n2.  Download the new Electron app from the assets below.\\n\\n### For New Users or Versions Below v1.0.0\\nPlease refer to the [new deployment documentation](https://docs.llmvtuber.com/docs/quick-start) for installation instructions.\\n\\n### Download Files\\nIf you are here because you read the documentation, download the zip file and the Electron app below.\\nDownload both of these files:\\n1.  The Electron app for your OS.\\n2.  The language-specific ZIP file:\\n    -   English: `Open-LLM-VTuber-v1.2.0-en.zip`\\n    -   Chinese: `Open-LLM-VTuber-v1.2.0-zh.zip`\\n\\nNote: The ZIP files are identical except for the language of the configuration file. Both packages include the SenseVoiceSmall model file to ensure accessibility for users in Mainland China.\\n\\n## Appendix\\n\\n### MCP examples tested in Open LLM Vtuber\\n\\n[mcp-server-browserbase](https://github.com/browserbase/mcp-server-browserbase/tree/main/stagehand)\\n![image](https://hackmd.io/_uploads/HyvAAkGgxg.png)\\n\\n[ScreenPilot](https://github.com/Mtehabsim/ScreenPilot)\\n![1DfLpUV2Hvu8n7E](https://hackmd.io/_uploads/S14Ufgzxll.png)\\n\\n## Faster download links for Chinese users \u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684(\u76f8\u5bf9)\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5\\nOpen-LLM-VTuber-v1.2.0-zh.zip (\u5305\u542b sherpa onnx asr \u7684 sense-voice \u6a21\u578b\uff0c\u5c31\u4e0d\u7528\u518d\u4ecegithub\u4e0a\u62c9\u53d6\u4e86)\\n- [Open-LLM-VTuber-v1.2.0-en.zip](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.2.0/Open-LLM-VTuber-v1.2.0-en.zip)\\n- [Open-LLM-VTuber-v1.2.0-zh.zip](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.2.0/Open-LLM-VTuber-v1.2.0-zh.zip)\\n\\nopen-llm-vtuber-1.2.0-setup.exe (\u684c\u9762\u7248\u524d\u7aef\uff0cWindows) (\u6ce8\u610f\uff0c\u8fd9\u53ea\u5305\u542b\u524d\u7aef)\\n- [open-llm-vtuber-1.2.0-setup.exe](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.2.0/open-llm-vtuber-1.2.0-setup.exe)\\n\\nopen-llm-vtuber-1.2.0.dmg (\u684c\u9762\u7248\u524d\u7aef\uff0cmacOS) (\u6ce8\u610f\uff0c\u8fd9\u53ea\u5305\u542b\u524d\u7aef)\\n- [open-llm-vtuber-1.2.0.dmg](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.2.0/open-llm-vtuber-1.2.0.dmg)"},{"id":"v1.1.0-release","metadata":{"permalink":"/en/blog/v1.1.0-release","editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/blog/2025-02-20-v1-1-0-release.md","source":"@site/i18n/en/docusaurus-plugin-content-blog/2025-02-20-v1-1-0-release.md","title":"1.1.0 Release","description":"Version 1.1.0 Release","date":"2025-02-20T00:00:00.000Z","tags":[{"inline":false,"label":"Release","permalink":"/en/blog/tags/release","description":"Version Release Note"}],"readingTime":2.525,"hasTruncateMarker":true,"authors":[{"name":"Yi-Ting Chiu","title":"yey","url":"https://github.com/t41372","page":{"permalink":"/en/blog/authors/tim"},"socials":{"github":"https://github.com/t41372"},"imageURL":"https://github.com/t41372.png","key":"tim"},{"name":"Ethan Lee","title":"qwq","url":"https://github.com/ylxmf2005","page":{"permalink":"/en/blog/authors/ethan"},"socials":{"github":"https://github.com/ylxmf2005"},"imageURL":"https://github.com/ylxmf2005.png","key":"ethan"}],"frontMatter":{"title":"1.1.0 Release","description":"Version 1.1.0 Release","slug":"v1.1.0-release","authors":["tim","ethan"],"tags":["release"],"image":"https://i.imgur.com/mErPwqL.png","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"1.2.0 Release","permalink":"/en/blog/v1.2.0-release"},"nextItem":{"title":"1.0.1 Release","permalink":"/en/blog/v1.0.1-release"}},"content":"## What\'s Changed\\n\\n### Major Features\\n* Implemented group chat functionality (@ylxmf2005)\\n* Added Silero-VAD voice activity detection (@AnyaCoder)\\n* Added CosyVoice2 text-to-speech support (@Warma10032)\\n* Added frontend ASR/TTS tools accessible at `http://localhost:web-tool`\\n  - Users can now directly use the project\'s speech recognition and text-to-speech engines\\n* Introduced one-click CUDA-ready setup using pixi (@mokurin000)\\n* Improved configuration management and update mechanism:\\n  - `conf.yaml` is no longer tracked in git\\n  - New config template system for generating and updating `conf.yaml` during upgrades\\n\\n\x3c!-- truncate --\x3e\\n\\n### Bug Fixes & Improvements\\n* Fixed sentence divider issues\\n* Fixed system prompt override bug for certain LLMs\\n* Removed deprecated `prompts/persona` directory (unused since v1.0.0)\\n* Major codebase refactoring of conversation and handler components (@ylxmf2005)\\n\\n### New Contributors\\n* @mokurin000\\n* @AnyaCoder\\n* @Warma10032\\n\\n**Full Changelog**: https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/compare/v1.0.0...v1.1.0\\n\\n\\n## Which files should I get? \u6211\u5e94\u8be5\u4e0b\u8f7d\u54ea\u4e9b\u6587\u4ef6\uff1f\\n\\n### For Existing Open-LLM-VTuber Users (v1.0.0 or newer) \u73b0\u6709 Open-LLM-VTuber \u7528\u6237\uff08v1.0.0 \u6216\u66f4\u65b0\u7248\u672c\uff09\\n1. Run `uv run upgrade.py` to update to the latest version \u8fd0\u884c `uv run upgrade.py` \u6765\u66f4\u65b0\u5230\u6700\u65b0\u7248\u672c\\n2. Download the new electron app from the releases section \u4ece\u53d1\u5e03\u533a(\u4e0b\u9762)\u4e0b\u8f7d\u65b0\u7684 electron \u5e94\u7528\u7a0b\u5e8f\\n\\n### For New Users or Versions Below v1.0.0 \u65b0\u7528\u6237\u6216 v1.0.0 \u4ee5\u4e0b\u7248\u672c\u7528\u6237\\nPlease refer to the [new deployment documentation](https://docs.llmvtuber.com/docs/quick-start) for installation instructions.\\n\u8bf7\u53c2\u8003[\u65b0\u90e8\u7f72\u6587\u6863](https://docs.llmvtuber.com/docs/quick-start)\u83b7\u53d6\u5b89\u88c5\u8bf4\u660e\u3002\\n\\n### Download Files \u4e0b\u8f7d\u6587\u4ef6\\nIf you are here because you read the documentation, download the zip file and the electron app below.\\nDownload both of these files:\\n1. The electron app\\n2. The language-specific ZIP file:\\n   - English: `Open-LLM-VTuber-v1.1.0-en.zip`\\n   - Chinese: `Open-LLM-VTuber-v1.1.0-zh.zip`\\n\\nNote: The ZIP files are identical except for the language of the configuration file. Both packages include the SenseVoiceSmall model file to ensure accessibility for Chinese users.\\n\\n\u5982\u679c\u60a8\u662f\u6309\u7167\u6587\u6863\u6307\u5f15\u6765\u5230\u8fd9\u91cc\u7684\uff0c\u8bf7\u4e0b\u8f7d\u4ee5\u4e0b\u7684 zip \u6587\u4ef6\u548c electron \u5e94\u7528\u7a0b\u5e8f\u3002\\n\u8bf7\u4e0b\u8f7d\u8fd9\u4e24\u4e2a\u6587\u4ef6\uff1a\\n1. electron \u5e94\u7528\u7a0b\u5e8f\\n2. \u5bf9\u5e94\u8bed\u8a00\u7684 ZIP \u6587\u4ef6\uff1a\\n   - \u82f1\u6587\u7248\uff1a`Open-LLM-VTuber-v1.1.0-en.zip`\\n   - \u4e2d\u6587\u7248\uff1a`Open-LLM-VTuber-v1.1.0-zh.zip`\\n\\n\u6ce8\u610f\uff1a\u8fd9\u4e9b ZIP \u6587\u4ef6\u9664\u4e86\u914d\u7f6e\u6587\u4ef6\u7684\u8bed\u8a00\u4e0d\u540c\u5916\u5b8c\u5168\u76f8\u540c\u3002\u4e24\u4e2a\u5305\u90fd\u5305\u542b SenseVoiceSmall \u6a21\u578b\u6587\u4ef6\u4ee5\u786e\u4fdd\u5185\u5730\u7528\u6237\u53ef\u4ee5\u6109\u5feb\u4f7f\u7528\u3002\\n\\n\\n## Faster download links for Chinese users \u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684(\u76f8\u5bf9)\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5\\nOpen-LLM-VTuber-v1.1.0-zh.zip (\u5305\u542b sherpa onnx asr \u7684 sense-voice \u6a21\u578b\uff0c\u5c31\u4e0d\u7528\u518d\u4ecegithub\u4e0a\u62c9\u53d6\u4e86)\\n- [Open-LLM-VTuber-v1.1.0-en.zip](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.1.0/Open-LLM-VTuber-v1.1.0-en.zip)\\n- [Open-LLM-VTuber-v1.1.0-zh.zip](https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.1.0/Open-LLM-VTuber-v1.1.0-zh.zip)\\n\\nopen-llm-vtuber-electron-1.1.0-frontend.exe (\u684c\u9762\u7248\u524d\u7aef\uff0cWindows)\\n- https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.1.0/open-llm-vtuber-electron-1.1.0-setup.exe\\n\\nopen-llm-vtuber-electron-1.1.0-frontend.dmg (\u684c\u9762\u7248\u524d\u7aef\uff0cmacOS)\\n- https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.1.0/open-llm-vtuber-electron-1.1.0.dmg"},{"id":"v1.0.1-release","metadata":{"permalink":"/en/blog/v1.0.1-release","editUrl":"https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Docs/tree/main/blog/2025-02-04-v1-0-1-release.md","source":"@site/i18n/en/docusaurus-plugin-content-blog/2025-02-04-v1-0-1-release.md","title":"1.0.1 Release","description":"Version 1.0.1 Release","date":"2025-02-04T00:00:00.000Z","tags":[{"inline":false,"label":"Release","permalink":"/en/blog/tags/release","description":"Version Release Note"}],"readingTime":5.53,"hasTruncateMarker":true,"authors":[{"name":"Yi-Ting Chiu","title":"yey","url":"https://github.com/t41372","page":{"permalink":"/en/blog/authors/tim"},"socials":{"github":"https://github.com/t41372"},"imageURL":"https://github.com/t41372.png","key":"tim"},{"name":"Ethan Lee","title":"qwq","url":"https://github.com/ylxmf2005","page":{"permalink":"/en/blog/authors/ethan"},"socials":{"github":"https://github.com/ylxmf2005"},"imageURL":"https://github.com/ylxmf2005.png","key":"ethan"}],"frontMatter":{"title":"1.0.1 Release","description":"Version 1.0.1 Release","slug":"v1.0.1-release","authors":["tim","ethan"],"tags":["release"],"image":"https://i.imgur.com/mErPwqL.png","hide_table_of_contents":false},"unlisted":false,"prevItem":{"title":"1.1.0 Release","permalink":"/en/blog/v1.1.0-release"}},"content":"This release marks a significant milestone for Open-LLM-VTuber, featuring a complete rewrite of the backend and frontend with over 240+ new commits, along with numerous enhancements and new features. If you were using a version before this, version `v1.0.0` is basically a new app.\\n\\n\u26a0\ufe0f Direct upgrades from older versions are impossible due to architectural changes. Please refer to our **[new documentation site](https://open-llm-vtuber.github.io/docs/intro)** for installation.\\n\\n(v1.0.0 had a bug after the release, so let\'s just ignore that and have the v1.0.1)\\n\\n| ![i4_pet_desktop](https://github.com/user-attachments/assets/06eff9dc-e141-4401-90ac-823b08662aae) | ![i1](https://github.com/user-attachments/assets/e0175aa3-62c8-4cde-9c6f-5d010727c04f) |\\n|:---:|:---:|\\n| ![i3](https://github.com/user-attachments/assets/082d8f29-9b48-4dbb-87f6-0f12d89a92f2) | ![i2](https://github.com/user-attachments/assets/f6b50eda-8187-4d37-b39b-a34e33683328) |\\n![i4](https://github.com/user-attachments/assets/fa4a5884-0ec7-4377-8a3b-204aafaf8ede) | ![i3_browser_world_fun](https://github.com/user-attachments/assets/8e0819d2-75dd-4ebf-97ab-399bf2d01795) |\\n\\n\x3c!-- truncate --\x3e\\n\\n## \u2728 Highlights\\n*   **Vision Capability:** Video chat with the AI.\\n*   **Desktop Pet Mode:** A new Desktop Pet Mode lets you have your VTuber companion directly on your desktop.\\n*   **Brand New Frontend:**  A completely redesigned frontend built with React, ChakuraUI, and Vite offers a modern user experience. Available as web and desktop apps, located in the [Open-LLM-VTuber-Web](https://github.com/Open-LLM-VTuber/Open-LLM-VTuber-Web) repository.\\n*   **Chat History Management:**  Implemented a system to store and retrieve conversation history, enabling persistent interactions with your AI.\\n*   **New LLM support:**  Many new (stateless) LLM providers are now supported (and refactored), including Ollama, OpenAI, Gemini, Claude, Mistral, DeepSeek, Zhipu, and llama.cpp.\\n*   **DeepSeek R1 Reasoning model support**: The reasoning chain will be displayed but not spoken. See your waifu\'s inner thoughts!\\n*   **Major Backend Rewrite:** The core of Open-LLM-VTuber has been rebuilt from the ground up, focusing on asynchronous operations, improved memory management, and a more modular architecture.\\n*   **Refactored Configuration:** The `conf.yaml` file was restructured, and `config_alts` has been renamed to `characters`.\\n* **TTS Preprocessor**: Text inside `asterisks`, `brackets`, `parentheses`, and `angle brackets` will no longer be spoken by the TTS.\\n*   **Dependency management:** Switched to `uv` for dependency management, removed unused dependencies such as `rich`, `playsound3`, and `sounddevice`.\\n*   **Documentation Site:** A comprehensive documentation site is now live at [https://open-llm-vtuber.github.io/](https://open-llm-vtuber.github.io/).\\n\\n## \ud83d\udccb Detailed Changes\\n\\n### \ud83e\uddee Backend\\n\\n*   **Architecture:**\\n    *   The project structure has been reorganized to use the `src/` directory.\\n    *   The backend is now fully asynchronous, improving responsiveness.\\n    *   CLI mode (`main.py`) has been removed.\\n    *   The \\"exit word\\" has been removed.\\n    *   Models are initialized and managed using `ServiceContext`, offering better memory management, particularly when switching characters.\\n    *   Refactored LLMs into `agent` and `stateless_llm`, supporting a wider range of LLMs with a new agent interface: `basic_memory_agent` and `hume_ai_agent`.\\n*   **LLM (Language Model) Enhancements:**\\n    *   New (and old but refactored) providers: Ollama, OpenAI (and any OpenAI Compatible API), Gemini, Claude, Mistral, DeepSeek, Zhipu, llama.cpp.\\n    *   `temperature` parameter added.\\n    *   No more tokens will be generated after interruption, improving the responsiveness of voice interruption.\\n    *   Ollama models are preloaded at startup, kept in memory for the server\'s duration, and unloaded at exit.\\n    *   Added a `hf_mirror` flag to specify whether to use the Hugging Face mirror source.\\n*   **TTS (Text-to-Speech) Enhancements:**\\n    *   TTS now generates multiple audio segments concurrently and sends them sequentially, reducing latency.\\n    *   New interruption logic for smoother transitions.\\n    *   Added filters (`asterisks`, `brackets`, `parentheses`) to prevent unwanted text from being spoken.\\n    *   Implemented `faster_first_response` feature to prioritize the synthesis and playback of the first sentence fragment, minimizing latency.\\n*   **ASR (Automatic Speech Recognition) Enhancements:**\\n    *   Made Sherpa-onnx ASR with the **SenseVoiceSmall int8** model the default for both English and Chinese presets, with automatic model download.\\n    *   Added a `provider` option for sherpa-onnx-asr.\\n*   **Other Improvements:**\\n    *   Chat log persistence is used to maintain conversation history.\\n    *   All `print` statements are replaced with `loguru` for structured logging.\\n    *   Added a Chinese configuration preset: `conf.CN.yaml`.\\n    *   Basic AI proactive speaking (experimental).\\n    *   Added some checks in the CI/CD process\\n    *   Added input/output type system to agents\\n    *   Added **Tencent Translate** in https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/pull/107\\n\\n### \ud83d\udda5\ufe0f Frontend\\n\\n*   **New frontend built with Electron, React, ChakuraUI, and Vite.**\\n*   **Multi-Mode in Single Codebase:**\\n    *   Web Mode: Browser interface\\n    *   Window Mode: Desktop window\\n    *   Pet Mode: Transparent desktop companion\\n    *   Seamless context sharing between Window and Pet modes, allowing for the preservation of settings, history, connections, and model states.\\n*   **Enhanced UI Features**\\n    *    Responsive layout with collapsible sidebar and footer\\n    *    Customizable Live2D model interactions: Mouse tracking for eye movement, Click-triggered animations, Drag & resize capabilities.\\n    *    Persistent local storage for user preference settings, including background, VAD configuration, Live2D size and interactions, and agent behavior.\\n    *    Supports viewing, loading, and deleting conversation history with streaming subtitles.\\n    *    (Electron pet-mode) A transparent, always-on-top desktop companion with click-through, non-interactive areas featuring draggable and hideable Live2D and UI, right-click menu controls.\\n    *    Camera and screen capturing panel\\n    *    Switch characters easily\\n\\n### \ud83d\udcd6 Documentation\\n\\n*   Rewritten README file.\\n*   New comprehensive documentation with a dedicated website.\\n\\n### \ud83e\uddf9 Cleanup\\n\\n*   Removed unused and legacy code, including `TaskQueue.py`, `scripts/install_piper_tts.py`, `model_manager_old.py`, `service_context_old.py`, `main.py`, `asr_with_vad`, `vad`, `start_cli`, `fake_llm`, `MemGPT`, the `pywhispercpp` submodule, and CoreML script.\\n*   Removed unused dependencies: `rich`, `playsound3`, `sounddevice`, among others.\\n*   Removed configuration options that are no longer relevant: `VOICE_INPUT_ON`, `MIC_IN_BROWSER`, `LIVE2D`, `EXTRA_SYSTEM_PROMPT_RAG`, `AI_NAME`, `USER_NAME`, `SAVE_CHAT_HISTORY`, `CHAT_HISTORY_DIR`, `RAG_ON`, `LLMASSIST_RAG_ON`, `SAY_SENTENCE_SEPARATELY`, `MEMORY_SNAPSHOT`, `PRELOAD_MODELS`, `tts_on`.\\n\\n\\n## \u26a0\ufe0f\u26a0\ufe0f\u26a0\ufe0f Critical Upgrade Notice\\n\\n\\n1. No Direct Upgrades - Previous installations are incompatible\\n\\n2. Fresh Install Required - Follow new documentation\\n\\n3. Config Changes - Back up existing configurations before migration\\n\\n### Why the Hassle? \ud83d\udca1\\n\\n1. UV dependency manager replaces legacy systems\\n2. Complete configuration schema overhaul\\n\\n\\n\\nPlease check out the [new documentation](https://open-llm-vtuber.github.io/docs/quick-start/) to install Open-LLM-VTuber again. Fortunately, thanks to `uv,` there should be fewer headaches during installation.\\n\\n\\n## \ud83c\udf89 Contributors\\n- @t41372, which is me\\n- @ylxmf2005, the creator of the new frontend, implemented LLM vision capability, chat history management, TTS concurrency, hume AI agent, better sentence division, a better live2d configuration, countless bug fixes, and more. He also wrote the majority of the documentation and provided countless insights. The version `v1.0.0` was a close collaboration with him and wouldn\'t have existed without his tremendous contribution.\\n- @Stewitch, who added the hf_mirror option and is currently working on a launcher for this project to streamline the installation and configuration process. It\'s still a work in progress but will be completed very soon. https://github.com/Stewitch/LiZhen\\n- @Fluchw, who added Tecent translator and helped us fix the translator bug.\\n\\nAnd all the other contributors who worked on this project in previous versions.\\n\\n\\n**Full Changelog**: https://github.com/Open-LLM-VTuber/Open-LLM-VTuber/compare/v0.5.2...v1.0.0\\n\\n\\n## Faster download links for Chinese users \u7ed9\u5185\u5730\u7528\u6237\u51c6\u5907\u7684(\u76f8\u5bf9)\u5feb\u901f\u7684\u4e0b\u8f7d\u94fe\u63a5\\nOpen-LLM-VTuber-v1.0.3.zip (\u5305\u542b sherpa onnx asr \u7684 sense-voice \u6a21\u578b\uff0c\u5c31\u4e0d\u7528\u518d\u4ecegithub\u4e0a\u62c9\u53d6\u4e86)\\n- https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/Open-LLM-VTuber-v1.0.3.zip\\n\\nopen-llm-vtuber-electron-1.0.0-frontend.exe (\u684c\u9762\u7248\u524d\u7aef\uff0cWindows)\\n- https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0-setup.exe\\n\\nopen-llm-vtuber-electron-1.0.0-frontend.dmg (\u684c\u9762\u7248\u524d\u7aef\uff0cmacOS)\\n- https://pub-17317087be374bc68161ac63de2022a5.r2.dev/v1.0.3/open-llm-vtuber-electron-1.0.0.dmg"}]}}')}}]);